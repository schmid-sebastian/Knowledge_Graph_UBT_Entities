{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "import unicodedata\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import string\n",
    "from itertools import permutations\n",
    "from tqdm import tqdm\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vorbereitungen\n",
    "Zunächst wird eine Liste von Subdomains der Uni Bayreuth auf ihre Verfügbarkeit gefiltert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_subdomains(path):\n",
    "    \"\"\"Liest alle Subdomains von www.uni-bayreuth.de ein.\"\"\"\n",
    "    subdomains = []\n",
    "    f = open(path + 'subdomains.txt', 'r')\n",
    "    line = f.readline()\n",
    "    while line:\n",
    "        subdomains.append(line.rstrip())\n",
    "        line = f.readline()\n",
    "    f.close()\n",
    "    return subdomains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_subdomains(subdomains):\n",
    "    \"\"\"Überprüft für eine Liste von subdomains ob sie\n",
    "    existieren und returned die, die es tun.\"\"\"\n",
    "    valid_subdomains = []\n",
    "    for url in tqdm(subdomains):\n",
    "        news_url = 'https://' + url\n",
    "        try:\n",
    "            page = requests.get(news_url)\n",
    "        except:\n",
    "            news_url = 'http://' + url\n",
    "            try:\n",
    "                page = requests.get(news_url)\n",
    "            except:\n",
    "                continue\n",
    "        if page:\n",
    "            valid_subdomains.append(news_url)\n",
    "    return list(set(valid_subdomains))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subdomains = get_all_subdomains('/home/ec2-user/data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_subdomains = check_subdomains(subdomains)\n",
    "valid_subdomains.extend(['https://www.mcii.uni-bayreuth.de/en/team/team-greiner/index.html',\n",
    "              'https://www.mcii.uni-bayreuth.de/en/team/team-agarwal/index.html',\n",
    "              'https://www.pes.uni-bayreuth.de/en/professorship/team/index.html'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# URLs von Team-Seiten sammeln\n",
    "Für die zuvor ermittelten Subdomains wird nun geprüft ob sie eine Team-Seite besitzen und falls ja, so wird diese gespeichert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_team_url(subdomains):\n",
    "    \"\"\"Erstellt eine Liste mit den Team-Seiten aller \n",
    "    Urls in der Liste subdomains.\"\"\"\n",
    "    team_urls = []\n",
    "    for url in subdomains:\n",
    "        endings = ['team/index.html', 'people/index.html']\n",
    "        for ending in endings:\n",
    "            complete = url + ending\n",
    "            page = requests.get(complete)\n",
    "            if page:\n",
    "                team_urls.append(complete)\n",
    "                break\n",
    "    return team_urls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_urls = get_team_url(valid_subdomains)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Team Seiten Scrapen\n",
    "Die zuvor ermittelten Team-Seiten werden nun gescraped. Dabei werden relevante Informationen wie z.B. E-Mail oder Telefonnummer extrahiert und im Knowledge-Graph Format (target --> relation --> source) abgespeichert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_team_info_in_kg_format(team_url):\n",
    "    \"\"\"Extrahiert die Informationen einer Lehrstuhlseite und speichert diese\n",
    "    korrekten Format für den Knowledge-Graph ab.\"\"\"\n",
    "    page = requests.get(team_url)\n",
    "    if not page:\n",
    "        return None\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    kg_global = []\n",
    "    lehrstuhl = get_chair_name(soup)\n",
    "    team_members = get_team_member_info(soup)\n",
    "    for member in team_members:\n",
    "        for i in range(1,len(member)):\n",
    "            name = replace_title(member[0])\n",
    "            if i < 2:\n",
    "                function = [name, member[1], lehrstuhl]\n",
    "            else:\n",
    "                temp = member[i].split()\n",
    "                function = [name, temp[0], ' '.join(temp[1:])]\n",
    "            function_clean = []\n",
    "            for test in function:\n",
    "                clean = test.strip()\n",
    "                clean = clean.strip(string.punctuation)\n",
    "                clean = clean.strip()\n",
    "                function_clean.append(clean)\n",
    "            for test in function_clean:\n",
    "                if (test == '') or (len(test) < 3):\n",
    "                    continue\n",
    "            kg_global.append(function_clean)\n",
    "    return kg_global\n",
    "\n",
    "def get_chair_name(soup):\n",
    "    \"\"\"Extrahiert den Namen des Lehrstuhls aus HTML-Texten.\"\"\"\n",
    "    lehrstuhl = str(soup.find_all('h3')[0])\n",
    "    lehrstuhl = re.sub('<.*?>', '', lehrstuhl)\n",
    "    lehrstuhl = lehrstuhl.split('–')[0].strip()\n",
    "    lehrstuhl = lehrstuhl.replace('&amp;', '&')\n",
    "    return lehrstuhl\n",
    "\n",
    "def get_team_member_info(soup):\n",
    "    \"\"\"Extrahiert für alle Mitarbeiter einer Lehrstuhlseite die\n",
    "    veröffentlichten Informationen.\"\"\"\n",
    "    member_section = soup.find_all('section', class_ = 'fse-block fse-dropzone text full')\n",
    "    all_members = []\n",
    "    for member in member_section:\n",
    "        member_info = member.find_all('p')\n",
    "        member_info = [str(x) for x in member_info]\n",
    "        member_info = ''.join(member_info)\n",
    "        member_info = member_info.replace('</p>', ' *_* ')\n",
    "        member_info = member_info.replace('</a>', ' *_* ')\n",
    "        member_info = member_info.replace('\\u200b', '')\n",
    "        member_info = re.sub('<br.*?>', ' *_* ', member_info)\n",
    "        team_member_clean = []\n",
    "        for info in member_info.split('*_*'):\n",
    "            team_member_clean.append((re.sub('<.*?>', '', info)).strip())\n",
    "        team_member_clean = [unicodedata.normalize('NFKD', x) for x in team_member_clean if x != '']\n",
    "        all_members.append(team_member_clean)\n",
    "    return all_members\n",
    "\n",
    "\n",
    "\n",
    "def replace_title(name):\n",
    "    \"\"\"Entfernt typische Titel im Namen eines Akademikers.\"\"\"\n",
    "    titles = ['Univ.', 'Prof.', 'Dr.', 'Professor', 'Doktor', 'Ing.', '-Ing.', 'rer.', 'PD', 'M.Sc.',\n",
    "              'M.A.', 'M.Eng.', 'LL.M.', 'M.F.A.', 'M.Mus.', 'M.Ed.', 'B.A.', 'BBA', 'FH', \n",
    "              'B.Sc.', 'LL.B.', 'B.Ed.', 'B.Eng.', 'B.F.A.', 'B.Mus.', 'B.M.A.', 'Dipl.',\n",
    "              'M.A', 'LL.M', 'LL.B', 'M.Sc', 'B.A', 'B.Sc', 'StB', 'Diplom-Jurist', 'Ass.',\n",
    "              'jur.', 'ass.', 'Jur.', 'Wirtschaftsjurist', 'Wirtschaftsjuristin', 'SpOec',\n",
    "              'Jun.', 'Mag.', 'nat.', 'M. Sc.', 'Wirtsch.', 'Kfm.' 'RA', 'LLP']\n",
    "    for title in titles:\n",
    "        name = name.replace(title, '')\n",
    "        name = name.strip(string.punctuation)\n",
    "        name = name.strip()\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 180/180 [00:32<00:00,  5.54it/s]\n"
     ]
    }
   ],
   "source": [
    "data_team = []\n",
    "for url in tqdm(team_urls):\n",
    "    try:\n",
    "        team_info = get_team_info_in_kg_format(url)\n",
    "    except Exception as e:\n",
    "        continue\n",
    "    if team_info:\n",
    "        data_team.extend(team_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_df = pd.DataFrame(data_team, columns = ['source', 'relation', 'target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CampusOnline Vorlesungsseiten Scrapen\n",
    "Nun werden für alle Vorlesungen im Sommersemester 2020 die relevanten Informationen wie z.B. Vorlesungsnummer oder Dozent extrahiert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "faculty_numbers = ['14093', '14094', '14095', '14096', '14097', '14098', '15794']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "lecture_links = []\n",
    "for faculty in faculty_numbers:\n",
    "    count = 1\n",
    "    while True:\n",
    "        base_url = 'https://campusonline.uni-bayreuth.de/ubto/wbLVAngebot.cbReloadLVOfferTable?pOrgNr=' + faculty + '&pPersonNr=&pSjNr=1709&pStpLvTypNr=-1&pPageNr=' + str(count)+ '&pSort=6%3B5&pFilter=null%3Ff_4_1%3DS&pGroup=K'\n",
    "        page = requests.get(base_url)\n",
    "        soup = BeautifulSoup(page.content, 'lxml')\n",
    "        row = soup.find_all('div', class_=\"L\")\n",
    "        if len(row) == 0:\n",
    "            break\n",
    "        for i in row:\n",
    "            a_tags = i.find_all('a')\n",
    "            for a in a_tags:\n",
    "                link = 'https://campusonline.uni-bayreuth.de/ubto/' + a['href']\n",
    "                lecture_links.append(link)\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|████████████████████████████▍                                                 | 1027/2820 [13:56<15:06,  1.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list index out of range bei Lecture: https://campusonline.uni-bayreuth.de/ubto/wbLv.wbShowLVDetail?pStpSpNr=267718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|██████████████████████████████████▋                                           | 1256/2820 [16:52<58:05,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list index out of range bei Lecture: https://campusonline.uni-bayreuth.de/ubto/wbLv.wbShowLVDetail?pStpSpNr=267899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|███████████████████████████████████████████████████▉                          | 1879/2820 [29:27<16:43,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list index out of range bei Lecture: https://campusonline.uni-bayreuth.de/ubto/wbLv.wbShowLVDetail?pStpSpNr=267973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████████████████████████████████████████████████████▊                       | 1980/2820 [31:04<15:37,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list index out of range bei Lecture: https://campusonline.uni-bayreuth.de/ubto/wbLv.wbShowLVDetail?pStpSpNr=267753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2820/2820 [47:19<00:00,  1.01s/it]\n"
     ]
    }
   ],
   "source": [
    "kg_data = []\n",
    "for lecture in tqdm(lecture_links):\n",
    "    try:\n",
    "        page = requests.get(lecture)\n",
    "        soup = BeautifulSoup(page.content, 'html.parser')\n",
    "        name = soup.find_all('span', class_ = 'bold')[1].text\n",
    "        name = ' '.join(name.split())\n",
    "        name = unicodedata.normalize('NFKD', name)\n",
    "        number = soup.find_all('span', class_ = 'bold')[2].text\n",
    "        number = unicodedata.normalize('NFKD', number)\n",
    "        lecture_type = soup.find_all('span', class_ = 'bold')[3].text\n",
    "        lecture_type = unicodedata.normalize('NFKD', lecture_type)\n",
    "        dozent = soup.find_all('a', attrs = {'target' : 'SVI'})[0].text\n",
    "        dozent = dozent.split(',')\n",
    "        dozent.reverse()\n",
    "        dozent = ' '.join(dozent).strip()\n",
    "        dozent = unicodedata.normalize('NFKD', dozent)\n",
    "        chair = soup.find_all('a', attrs = {'target' : 'tugonline'})[0].text\n",
    "        chair = re.sub('\\([^)]*\\)$', '', chair).strip()\n",
    "        chair = unicodedata.normalize('NFKD', chair)\n",
    "        kg_data.append([name, 'Vorlesungsnummer', number])\n",
    "        kg_data.append([name, 'Veranstaltungsart', lecture_type])\n",
    "        kg_data.append([name, 'Dozent', dozent])\n",
    "        kg_data.append([name, 'Veranstaltung von', chair])\n",
    "    except Exception as e:\n",
    "        print(e, 'bei Lecture:', lecture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "kg_df = pd.DataFrame(kg_data, columns=['source', 'relation', 'target'])\n",
    "team_df = team_df[team_df.source.str.len() <= 80]\n",
    "final = kg_df.append(team_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Knowledge Graph bereinigen\n",
    "Da teils fehlerhafte Informationen im Knowledge Graph enthalten sind, werden diese entfernt. Ferner werden die zahlreichen Relationen mithilfe eines Wörterbuchs vereinheitlicht um Synonyme auf eine globale Bezeichnung zu bringen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = final[~final['relation'].str.contains('@')]\n",
    "final = final[~final['relation'].str.contains('Lebenslauf')]\n",
    "final = final[~final['relation'].str.contains('Mehr')]\n",
    "final = final[final['target'] != '']\n",
    "final = final[~final['relation'].str.contains('Universite')]\n",
    "final = final[~final['source'].str.len() < 3]\n",
    "final = final[~final['target'].str.len() < 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ['Universitätsstraße', 'Universitätsstr.', 'Universität', 'University', 'Die', 'Beginn', 'in', 'im',\n",
    "          'auch', 'derzeit', '', 'Literatures', 'More', 'siehe', 'Public', 'B', 'Language', 'African', 'Erlangen',\n",
    "          'Zur', 'Scientific', 'For', 'Curriculum', '▹', '.', 'Das', 'Im Ruhestand', 'im Ruhestand', 'Nähere', \n",
    "          'z.Zt. in Elternzeit', 'Online', 'Vorlage']:\n",
    "    final = final[final['relation'] != i]\n",
    "final = final.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "relation_dict = {\n",
    "'vorlesungsnummer' : 'Vorlesungsnummer',\n",
    "'veranstaltungsart' : 'Veranstaltungsart',\n",
    "'dozent' : 'Dozent',\n",
    "'veranstaltung von' : 'Veranstaltung von',\n",
    "'head of research group' : 'Lehrstuhlinhaber',\n",
    "'telefon' : 'Telefon',\n",
    "'phone' : 'Telefon',\n",
    "'room' : 'Raum',\n",
    "'raum' : 'Raum',\n",
    "'gebäude' : 'Raum',\n",
    "'sprechstunde' : 'Sprechstunde',\n",
    "'consultation' : 'Sprechstunde',\n",
    "'consultation-hour' : 'Sprechstunde',\n",
    "'consultation-hours' : 'Sprechstunde',\n",
    "'hours' : 'Sprechstunde',\n",
    "'e-mail' : 'E-Mail',\n",
    "'email' : 'E-Mail',\n",
    "'zimmer' : 'Raum',\n",
    "'juniorprofessor' : 'Lehrstuhlinhaber',\n",
    "'juniorprofessorin' : 'Lehrstuhlinhaber',\n",
    "'juniorprofessur' : 'Lehrstuhlinhaber',\n",
    "'professur' : 'Lehrstuhlinhaber',\n",
    "'lehrbeauftragterin' : 'Wissenschaftlicher Mitarbeiter',\n",
    "'Building' : 'raum',\n",
    "'office' : 'Sprechstunde',\n",
    "'secretary' : 'Sekretariat',\n",
    "'sekretärin' : 'Sekretariat',\n",
    "'technician' : 'Techniker', \n",
    "'graduate student' : 'Studentischer Mitarbeiter',\n",
    "'undergraduate student' : 'Studentischer Mitarbeiter',\n",
    "'phd student' : 'Doktorand',\n",
    "'teacher' : 'Wissenschaftlicher Mitarbeiter',\n",
    "'professor' : 'Lehrstuhlinhaber',\n",
    "'consulation' : 'Sprechstunde',\n",
    "'group leader' : 'Lehrstuhlinhaber',\n",
    "'academic councillor' : 'Akademischer Rat',\n",
    "'academic counselor' : 'Akademischer Rat',\n",
    "'secretariat' : 'Sekretariat',\n",
    "'technical assistant' : 'Techniker',\n",
    "'phd' : 'Doktorand',\n",
    "'doktorandin' : 'Doktorand',\n",
    "'doktorant' : 'Doktorand',\n",
    "'doktorantin' : 'Doktorand',\n",
    "'sprechzeit' : 'Sprechstunde',\n",
    "'wissenschaftlicher mitarbeiter' : 'Wissenschaftlicher Mitarbeiter',\n",
    "'wissenschaftliche mitarbeiterin' : 'Wissenschaftlicher Mitarbeiter',\n",
    "'wiss. mitarbeiter' : 'Wissenschaftlicher Mitarbeiter',\n",
    "'wiss. mitarbeiterin' : 'Wissenschaftlicher Mitarbeiter',\n",
    "'studentische hilfskraft' : 'Studentischer Mitarbeiter',\n",
    "'lehrstuhlinhaberin' : 'Lehrstuhlinhaber',\n",
    "'sekretariat' : 'Sekretariat',\n",
    "'tel' : 'Telefon',\n",
    "'mail' : 'E-Mail',\n",
    "'fax' : 'Fax',\n",
    "'fox' : 'Fax',\n",
    "'research assistant' : 'Wissenschaftlicher Mitarbeiter',\n",
    "'master studentin' : 'Studentischer Mitarbeiter',\n",
    "'master student' : 'Studentischer Mitarbeiter',\n",
    "'akad. rat a.z' : 'Akademischer Rat',\n",
    "'akad. rat. a.z.' : 'Akademischer Rat',\n",
    "'chairholder' : 'Lehrstuhlinhaber',\n",
    "'acad. director' : 'Akademischer Rat',\n",
    "'staff scientist' : 'Wissenschaftlicher Mitarbeiter',\n",
    "'ph.d. student' : 'Doktorand',\n",
    "'ph d student' : 'Doktorand',\n",
    "'ph d. student' : 'Doktorand',\n",
    "'bachelor student' : 'Studentischer Mitarbeiter',\n",
    "'bachelor studentin' : 'Studentischer Mitarbeiter',\n",
    "'lehrkraft' : 'Wissenschaftlicher Mitarbeiter',\n",
    "'physical engineer' : 'Wissenschaftlicher Mitarbeiter',\n",
    "'vertretungsprofessur' : 'Vertretungsprofessur',\n",
    "'doktorand' : 'Doktorand',\n",
    "'sprechzeit' : 'Sprechstunde',\n",
    "'sprechzeiten' : 'Sprechstunde',\n",
    "'Sprechstunden' : 'Sprechstunde',\n",
    "'akademische rätin' : 'Akademischer Rat',\n",
    "'lehrstuhlinhaber' : 'Lehrstuhlinhaber',\n",
    "'lehrstuhlinhaberin' : 'Lehrstuhlinhaber',\n",
    "'wissenschaftliche hilfskraft' : 'Wissenschaftlicher Mitarbeiter',\n",
    "'inhaberin' : 'Lehrstuhlinhaber',\n",
    "'inhaber' : 'Lehrstuhlinhaber',\n",
    "'professorin' : 'Lehrstuhlinhaber',\n",
    "'adresse' : 'Raum',\n",
    "'technische assistentin' : 'Wissenschaftlicher Mitarbeiter',\n",
    "'technischer assistent' : 'Wissenschaftlicher Mitarbeiter',\n",
    "'student assistant' : 'Studentischer Mitarbeiter',\n",
    "'teamassistenz' : 'Wissenschaftlicher Mitarbeiter',\n",
    "'academic council' : 'Akademischer Rat',\n",
    "'lehrbeauftragte' : 'Lehrstuhlinhaber',\n",
    "'lehrbeauftragter' : 'Lehrstuhlinhaber',\n",
    "'projektmitarbeiter' : 'Wissenschaftlicher Mitarbeiter',\n",
    "'projektmitarbeiterin' : 'Wissenschaftlicher Mitarbeiter',\n",
    "'büro' : 'Raum',\n",
    "'building' : 'Raum',\n",
    "'akademischer rat' : 'Akademischer Rat',\n",
    "'akademische rätin' : 'Akademischer Rat',\n",
    "'akademischer oberrat' : 'Akademischer Rat',\n",
    "'akademische oberrätin' : 'Akademischer Rat',\n",
    "'akademischer direktor' : 'Akademischer Direktor', \n",
    "'akademic director' : 'Akademischer Direktor', \n",
    "'alumni' : 'Alumni',\n",
    "'bürozeiten' : 'Sprechstunde',\n",
    "'laboratory assistant' : 'Wissenschaftlicher Mitarbeiter',\n",
    "'post-doc' : 'Wissenschaftlicher Mitarbeiter',\n",
    "'post doc' : 'Wissenschaftlicher Mitarbeiter',\n",
    "'masterand' : 'Studentischer Mitarbeiter',\n",
    "'masterandin' : 'Studentischer Mitarbeiter',\n",
    "'bachelorand' : 'Studentischer Mitarbeiter',\n",
    "'bachelorandin' : 'Studentischer Mitarbeiter',\n",
    "'assistent' : 'Wissenschaftlicher Mitarbeiter',\n",
    "'assistentin' : 'Wissenschaftlicher Mitarbeiter',\n",
    "'student' : 'Studentischer Mitarbeiter',\n",
    "'sprechstunde' : 'Sprechstunde',\n",
    "'öffnungszeit' : 'Sprechstunde',\n",
    "'öffnungszeiten' : 'Sprechstunde',\n",
    "'mitarbeiterin' : 'Wissenschaftlicher Mitarbeiter',\n",
    "'mitarbeiter' : 'Wissenschaftlicher Mitarbeiter',\n",
    "'angestellter' : 'Wissenschaftlicher Mitarbeiter',\n",
    "'habilitandin' : 'Habilitand',\n",
    "'habilitand' : 'Habilitand',\n",
    "'address' : 'Raum', \n",
    "'sprechstunden' : 'Sprechstunde',\n",
    "'honorarprofessor' : 'Honorarprofessor',\n",
    "'honorarprofessorin' : 'Honorarprofessor',\n",
    "'lehrstuhlvertretung' : 'Lehrstuhlvertretung',\n",
    "'mitarbeiter' : 'Wissenschaftlicher Mitarbeiter',\n",
    "'mitarbeiterin' : 'Wissenschaftlicher Mitarbeiter',\n",
    "'leiter' : 'Leiter',\n",
    "'leiterin' : 'Leiter',\n",
    "'austausch-doktorand' : 'Doktorand',\n",
    "'bachelor-student' : 'Studentischer Mitarbeiter',\n",
    "'bachelor-studentin' : 'Studentischer Mitarbeiter',\n",
    "'master-student' : 'Studentischer Mitarbeiter',\n",
    "'master-studentin' : 'Studentischer Mitarbeiter',\n",
    "'postdoc' : 'Wissenschaftlicher Mitarbeiter',\n",
    "'head of research' : 'Lehrstuhlinhaber',\n",
    "'homepage' : 'Webseite',\n",
    "'website' : 'Webseite',\n",
    "'webseite' : 'Webseite',\n",
    "'studentische hilfskräfte' : 'Studentischer Mitarbeiter',\n",
    "'research scientist' : 'Wissenschaftlicher Mitarbeiter',\n",
    "'lecturer' : 'Wissenschaftlicher Mitarbeiter',\n",
    "'telefax' : 'Fax',\n",
    "'assistant' : 'Wissenschaftlicher Mitarbeiter',\n",
    "'privatdozent' : 'Privatdozent',\n",
    "'privatdozentin' : 'Privatdozent',\n",
    "'arbeitsgruppenleiter' : 'Arbeitsgruppenleiter',\n",
    "'leitung' : 'Leitung',\n",
    "'head' : 'Leitung',\n",
    "'head of chair' : 'Lehrstuhlinhaber',\n",
    "'wissenschaftliche' : 'Wissenschaftlicher Mitarbeiter',\n",
    "'wissenschaftlicher' : 'Wissenschaftlicher Mitarbeiter',\n",
    "'telefonsprechstunde' : 'Sprechstunde',\n",
    "'studierendensekretariat' : 'Sekretariat',\n",
    "'promovendin' : 'Doktorand',\n",
    "'promovierende' : 'Doktorand',\n",
    "'promovend' : 'Doktorand',\n",
    "'promovierender' : 'Doktorand',\n",
    "'fachleitung' : 'Leitung',\n",
    "'techniker' : 'Techniker',\n",
    "'technikerin' : 'Techniker',\n",
    "'fachleiter' : 'Leitung',\n",
    "'fachleiterin' : 'Leitung',\n",
    "'lehrstuhlsekretärin' : 'Sekretariat',\n",
    "'lektor' : 'Wissenschaftlicher Mitarbeiter',\n",
    "'w1-juniorprofessorin' : 'Lehrstuhlinhaber',\n",
    "'associate' : 'Wissenschaftlicher Mitarbeiter',\n",
    "'studentische' : 'Studentischer Mitarbeiter',\n",
    "'studiengangsmoderator' : 'Studiengangsmoderator',\n",
    "'studiengangsmoderatorin' : 'Studiengangsmoderator',\n",
    "'dekan' : 'Dekan',\n",
    "'verwaltungsangestellte' : 'Sekretariat',\n",
    "'technik' : 'Techniker',\n",
    "'reinraumtechniker' : 'Techniker',\n",
    "'emeritus' : 'Emeritus',\n",
    "'principal investigator' : 'Wissenschaftlicher Mitarbeiter',\n",
    "'studiengangskoordinatorin' : 'Studiengangskoordinator',\n",
    "'studiengangskoordinator' : 'Studiengangskoordinator',\n",
    "'oder' : 'E-Mail',\n",
    "'gründungsdekan' : 'Dekan',\n",
    "'geschäftsführer' : 'Geschäftsführer',\n",
    "'appointments' : 'Sprechstunde',\n",
    "'appointment' : 'Sprechstunde',\n",
    "'scholar' : 'Wissenschaftlicher Mitarbeiter'\n",
    "}\n",
    "\n",
    "for i in relation_dict.copy():\n",
    "    relation_dict[unicodedata.normalize('NFKD', i)] = relation_dict[i]\n",
    "    \n",
    "weekdays = ['montag', 'monday', 'dienstag', 'tuesday', 'mittwoch', 'wednesday', 'donnerstag', 'thursday',\n",
    "            'freitag', 'friday', 'samstag', 'saturday', 'sonntag', 'sunday', 'mo', 'di', 'mi', 'do', 'fr', 'sa', 'so']\n",
    "\n",
    "def check_for_wrong_relation_format(row):\n",
    "    \"\"\"Der typische Fehler, dass Informationen zwar korrekt, aber in der falschen Reihenfolge\n",
    "    sind (relation wurde als Knoten erfasst), wird hiermit beseitigt.\"\"\"\n",
    "    relation = row['relation']\n",
    "    target = row['target']\n",
    "    relation = ''.join((char if char not in string.punctuation else ' ') for char in relation).split()\n",
    "    if relation[0].lower() in weekdays:\n",
    "        target = ' '.join(relation) + target\n",
    "        relation = 'Sprechstunde'\n",
    "        return True, relation, target\n",
    "    if len(relation) > 1:\n",
    "        relation_first = relation_dict.get(relation[0].lower(), 'not found')\n",
    "        if (relation_first == 'Telefon') or (relation_first == 'Fax') or (relation_first == 'Raum') or (relation_first == 'E-Mail') or (relation_first == 'Sprechstunde'):\n",
    "            if target.isalpha():\n",
    "                target = ' '.join(relation[1:]) + target\n",
    "                relation = relation_first\n",
    "            else:\n",
    "                target = ' '.join(relation[1:])\n",
    "                relation = relation_first\n",
    "            return True, relation, target\n",
    "    return False, relation, target\n",
    "\n",
    "for i in range(len(final)):\n",
    "    to_change, relation, target = check_for_wrong_relation_format(final.iloc[i])\n",
    "    if to_change:\n",
    "        final.loc[i, 'relation'] = relation\n",
    "        final.loc[i, 'target'] = target\n",
    "\n",
    "not_found = []\n",
    "def clean_relations(relation):\n",
    "    \"\"\"Vereinheitlicht die Relationen regelbasiert.\"\"\"\n",
    "    global not_found\n",
    "    relation = relation.lower()\n",
    "    right_relation = relation_dict.get(relation, 'not found')\n",
    "    if right_relation == 'not found':\n",
    "        right_relation = check_relation_permutations(relation)\n",
    "    if right_relation == 'not found':\n",
    "        not_found.append(relation)\n",
    "        return relation\n",
    "    else:\n",
    "        return right_relation\n",
    "    \n",
    "\n",
    "def check_relation_permutations(relation):\n",
    "    \"\"\"Ermittelt alle Permutationen der Wörter einer Relation.\"\"\"\n",
    "    relation = relation.split(' ')\n",
    "    unicode_relation = [unicodedata.normalize('NFKD', x) for x in relation]\n",
    "    relation_clean = [x.strip(string.punctuation) for x in unicode_relation]\n",
    "    relation = [x.strip() for x in relation_clean]\n",
    "    if len(relation) > 10:\n",
    "        perm = permutations(relation, 1)\n",
    "        for j in perm:\n",
    "            perm_joined = j[0]\n",
    "            if perm_joined in relation_dict:\n",
    "                return relation_dict[perm_joined]\n",
    "            else:\n",
    "                return 'not found'\n",
    "    for i in range(len(relation), 0, -1):\n",
    "        perm = permutations(relation, i)\n",
    "        for j in perm:\n",
    "            perm_joined = ' '.join(j)\n",
    "            if perm_joined in relation_dict:\n",
    "                return relation_dict[perm_joined]\n",
    "    return 'not found'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "final['relation_cleaned'] = final['relation'].apply(clean_relations)\n",
    "final = final[['source' , 'relation_cleaned', 'target']]\n",
    "final.columns = ['source', 'relation', 'target']\n",
    "final = final[~final['relation'].isin(not_found)]\n",
    "\n",
    "professoren = final[final['relation'] == 'Lehrstuhlinhaber'].drop_duplicates()\n",
    "chair_dict = dict(zip(professoren.source.to_list(), professoren.target.to_list()))\n",
    "\n",
    "for key in chair_dict.keys():\n",
    "    try:\n",
    "        veranstaltungen = final[final['target'] == key].source.to_list()\n",
    "        chair_to_change = final[(final['source'].isin(veranstaltungen)) & (final['relation'] == 'Veranstaltung von')].target.value_counts().index[0]\n",
    "        final.loc[final['target'] == chair_to_change, 'target'] = chair_dict[key]\n",
    "    except Exception as e:\n",
    "        print(e, 'at', key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mensa-Speisepläne Scrapen\n",
    "Um Informationen über das Menü in der Mensa zur Verfügung zu stellen, wird nun die Webseite des Studentenwerks gescraped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "iso = datetime.datetime.today().isocalendar()\n",
    "d = str(iso[0]) + '-W' + str(iso[1]-1)\n",
    "dates = []\n",
    "for i in range(0,7):\n",
    "    r = datetime.datetime.strptime(d + '-' + str(i), \"%Y-W%W-%w\")\n",
    "    dates.append(str(r).split()[0])\n",
    "dates.sort()\n",
    "dayname = ['Montag', 'Dienstag', 'Mittwoch', 'Donnerstag', 'Freitag', 'Samstag', 'Sonntag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "meal_list = []\n",
    "for date in range(len(dates)):\n",
    "    base_url = 'https://www.studentenwerk-oberfranken.de/essen/speiseplaene/bayreuth/frischraum/'\n",
    "    page = requests.get(base_url + dates[date] + '.html')\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    temp = soup.find_all('div', class_ = \"tx-bwrkspeiseplan__hauptgerichte\")\n",
    "    meals = []\n",
    "    if len(temp) < 2:\n",
    "        continue\n",
    "    for i in temp[1].find_all('td')[::3]:\n",
    "        raw = i.text.split('\\n')[0].strip()\n",
    "        clean = raw.split('(')[0].strip()\n",
    "        meals.append(clean)\n",
    "    meal_list.append(meals[:-2])\n",
    "kg_format = []\n",
    "for j in range(len(meal_list)):\n",
    "    kg_format.append([dayname[j], 'Mensa', str(meal_list[j]).strip('[]').strip(\"''\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = final.append(pd.DataFrame(kg_format, columns=['source', 'relation', 'target']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Klausurenplan\n",
    "Um Informationen über Klausurentermine etc. bereitzustellen, wird hier ein gegebener Klausurenplan in den Knowledge Graph eingefügt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "exams = []\n",
    "f = open('Klausuren.txt', 'r', encoding='utf-8')\n",
    "line = f.readline()\n",
    "while line:\n",
    "    exams.append(line.rstrip())\n",
    "    line = f.readline()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "exams_ordered = []\n",
    "last = 0\n",
    "for i in range(len(exams)):\n",
    "    if '|' in exams[i]:\n",
    "        exams_ordered.append(exams[last:i])\n",
    "        last = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_ordered = []\n",
    "for exam_chunk in exams_ordered:\n",
    "    date = exam_chunk.pop(0)\n",
    "    last = 0\n",
    "    for i in range(len(exam_chunk)):\n",
    "        if ';' in exam_chunk[i]:\n",
    "            temp = [date]\n",
    "            temp.extend(exam_chunk[last:i+1])\n",
    "            last = i + 1\n",
    "            info_ordered.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "kg_format = []\n",
    "for exam in info_ordered:\n",
    "    exam = [x.strip(';') for x in exam]\n",
    "    date = exam[0]\n",
    "    name = exam[1]\n",
    "    kg_format.append([name, 'Klausur', date + ' ' + ' '.join(exam[2:])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = final.append(pd.DataFrame(kg_format, columns = ['source', 'relation', 'target']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# E-Learning Links Scrapen\n",
    "Um schnell den Link zu der E-Learning Page einer Veranstaltung zu bekommen, wird nun das E-Learning der Uni Bayreuth gescraped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_elearning(urls):\n",
    "    \"\"\"Scraped für eine Liste von URLs die Elearning Links zu Kursen.\"\"\"\n",
    "    new_urls = []\n",
    "    kg_data = []\n",
    "    for url in tqdm(urls):\n",
    "        page = requests.get(url)\n",
    "        soup = BeautifulSoup(page.content, 'html.parser')\n",
    "        temp = soup.find_all('div', class_ = 'subcategories')\n",
    "        if len(temp) == 0:\n",
    "            temp = soup.find_all('div', class_ = 'content')\n",
    "            courses = temp[0].find_all('h3', class_='coursename')\n",
    "            for course in courses:\n",
    "                info = course.find_all('a')[0]\n",
    "                new_url = info['href']\n",
    "                coursename = info.text\n",
    "                coursename = clean_course_name(coursename)\n",
    "                new_urls.append(new_url)\n",
    "                kg_data.append([coursename, 'e-Learning', new_url])\n",
    "        else:\n",
    "            for a in temp[0].find_all('a'):\n",
    "                kg_data.append([clean_course_name(a.text), 'e-Learning', a['href']])\n",
    "                new_urls.append(a['href'])\n",
    "    return len(new_urls) > 0, new_urls, kg_data\n",
    "\n",
    "def clean_course_name(course_name):\n",
    "    \"\"\"Bereinigt den Kursnamen um Strings wie z.B. SoSe 2020.\"\"\"\n",
    "    common_expressions = ['SS2020', 'SoSe2020', 'SS20',\n",
    "                         'SS2020', 'SS 2020', 'SS 20',\n",
    "                         'SoSe 2020', 'SoSe 20', 'Sommersemester 20',\n",
    "                         'Sommersemester 2020', '2020', '20', 'SS',\n",
    "                         'SoSe', 'Sommersemester'] \n",
    "    course_name = re.sub(\"[\\(\\[].*?[\\)\\]]\", \"\", course_name)\n",
    "    course_name = ' '.join([x for x in course_name.split() if x not in common_expressions]).strip()\n",
    "    return course_name\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.36s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:11<00:00,  1.23s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 60/60 [01:25<00:00,  1.43s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 434/434 [07:07<00:00,  1.01it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1178/1178 [07:32<00:00,  2.61it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:10<00:00,  2.23it/s]\n"
     ]
    }
   ],
   "source": [
    "keep_going = True\n",
    "new_urls = ['https://elearning.uni-bayreuth.de/course/index.php?categoryid=4140']\n",
    "kg_data_global = []\n",
    "while keep_going:\n",
    "    keep_going, new_urls, kg_data = scrape_elearning(new_urls)\n",
    "    kg_data_global.extend(kg_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = final.append(pd.DataFrame(kg_data_global, columns = ['source', 'relation', 'target']))\n",
    "final.to_csv('/home/ec2-user/data/knowledge_graph_relations_cleaned.csv', index = False, sep = '|')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
